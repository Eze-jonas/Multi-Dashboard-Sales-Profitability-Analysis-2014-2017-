{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0da8b07-2301-4e96-a121-164b64537b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "(9994, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Specify file path\n",
    "file_path = r\"C:\\Users\\USER\\Documents\\Sales_Data\\Superstore.csv\"\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "#df = pd.read_csv(file_path)\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Print the shape of the DataFrame (rows, columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d580f4-2613-465c-9012-10a6bd67c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " These are the data types of the variables:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row ID             int64\n",
       "Order ID          object\n",
       "Order Date        object\n",
       "Ship Date         object\n",
       "Ship Mode         object\n",
       "Customer ID       object\n",
       "Customer Name     object\n",
       "Segment           object\n",
       "Country           object\n",
       "City              object\n",
       "State             object\n",
       "Postal Code        int64\n",
       "Region            object\n",
       "Product ID        object\n",
       "Category          object\n",
       "Sub-Category      object\n",
       "Product Name      object\n",
       "Sales            float64\n",
       "Quantity           int64\n",
       "Discount         float64\n",
       "Profit           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data type of the variables of the dataset\n",
    "print( \" These are the data types of the variables:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839f5f1e-a3cb-48da-b507-e6128b3d28f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No row is completely empty\n"
     ]
    }
   ],
   "source": [
    "# Check if there is a copletely empty rows in the dataset\n",
    "completely_empty_rows = df[df.isnull( ).all(axis = 1)]\n",
    "if not completely_empty_rows.empty:\n",
    "    print(\"Number of completely empty rows:{len(completely_empty_rows)}\")\n",
    "else:\n",
    "    print(\"No row is completely empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c92a45d-08c3-43fc-9f23-4793f43b26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no duplicate rows:\n"
     ]
    }
   ],
   "source": [
    "# Check if there is a duplicated rows\n",
    "duplicated_rows = df[df.duplicated( )]\n",
    "if not duplicated_rows.empty:\n",
    "    print(f\"Number of duplicated rows:{len(duplicated_rows)}\")\n",
    "    print(\"Duplicated rows are:\")\n",
    "    print(duplicated_rows)\n",
    "else:\n",
    "    print(\"There is no duplicate rows:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aa27d117-da92-4761-b38d-75a4c98d4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the variables and their amount of missing values:\n",
      "Row ID           0\n",
      "Order ID         0\n",
      "Order Date       0\n",
      "Ship Date        0\n",
      "Ship Mode        0\n",
      "Customer ID      0\n",
      "Customer Name    0\n",
      "Segment          0\n",
      "Country          0\n",
      "City             0\n",
      "State            0\n",
      "Postal Code      0\n",
      "Region           0\n",
      "Product ID       0\n",
      "Category         0\n",
      "Sub-Category     0\n",
      "Product Name     0\n",
      "Sales            0\n",
      "Quantity         0\n",
      "Discount         0\n",
      "Profit           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine the dataset for missing values(NaN)\n",
    "missing_values = df.isna().sum()\n",
    "print(f\"These are the variables and their amount of missing values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace63a1c-867b-4f55-92f9-b51b78d62003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                            Column by column analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "807e2dbb-6e02-4d4e-90e6-cd9ba2457c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Second Class' 'Standard Class' 'First Class' 'Same Day']\n"
     ]
    }
   ],
   "source": [
    "# Ship mode column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Ship Mode\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac83be50-9250-4c3d-945e-1a15b1ff27f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Consumer' 'Corporate' 'Home Office']\n"
     ]
    }
   ],
   "source": [
    "# Segment column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Segment\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2991d0a1-2725-4d9b-918a-ead8a12b8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['United States']\n"
     ]
    }
   ],
   "source": [
    "# Country column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Country\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ef1f78d6-92f1-495e-aa65-905fa378f47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Henderson' 'Los Angeles' 'Fort Lauderdale' 'Concord' 'Seattle'\n",
      " 'Fort Worth' 'Madison' 'West Jordan' 'San Francisco' 'Fremont'\n",
      " 'Philadelphia' 'Orem' 'Houston' 'Richardson' 'Naperville' 'Melbourne'\n",
      " 'Eagan' 'Westland' 'Dover' 'New Albany' 'New York City' 'Troy' 'Chicago'\n",
      " 'Gilbert' 'Springfield' 'Jackson' 'Memphis' 'Decatur' 'Durham' 'Columbia'\n",
      " 'Rochester' 'Minneapolis' 'Portland' 'Saint Paul' 'Aurora' 'Charlotte'\n",
      " 'Orland Park' 'Urbandale' 'Columbus' 'Bristol' 'Wilmington' 'Bloomington'\n",
      " 'Phoenix' 'Roseville' 'Independence' 'Pasadena' 'Newark' 'Franklin'\n",
      " 'Scottsdale' 'San Jose' 'Edmond' 'Carlsbad' 'San Antonio' 'Monroe'\n",
      " 'Fairfield' 'Grand Prairie' 'Redlands' 'Hamilton' 'Westfield' 'Akron'\n",
      " 'Denver' 'Dallas' 'Whittier' 'Saginaw' 'Medina' 'Dublin' 'Detroit'\n",
      " 'Tampa' 'Santa Clara' 'Lakeville' 'San Diego' 'Brentwood' 'Chapel Hill'\n",
      " 'Morristown' 'Cincinnati' 'Inglewood' 'Tamarac' 'Colorado Springs'\n",
      " 'Belleville' 'Taylor' 'Lakewood' 'Arlington' 'Arvada' 'Hackensack'\n",
      " 'Saint Petersburg' 'Long Beach' 'Hesperia' 'Murfreesboro' 'Layton'\n",
      " 'Austin' 'Lowell' 'Manchester' 'Harlingen' 'Tucson' 'Quincy'\n",
      " 'Pembroke Pines' 'Des Moines' 'Peoria' 'Las Vegas' 'Warwick' 'Miami'\n",
      " 'Huntington Beach' 'Richmond' 'Louisville' 'Lawrence' 'Canton'\n",
      " 'New Rochelle' 'Gastonia' 'Jacksonville' 'Auburn' 'Norman' 'Park Ridge'\n",
      " 'Amarillo' 'Lindenhurst' 'Huntsville' 'Fayetteville' 'Costa Mesa'\n",
      " 'Parker' 'Atlanta' 'Gladstone' 'Great Falls' 'Lakeland' 'Montgomery'\n",
      " 'Mesa' 'Green Bay' 'Anaheim' 'Marysville' 'Salem' 'Laredo' 'Grove City'\n",
      " 'Dearborn' 'Warner Robins' 'Vallejo' 'Mission Viejo' 'Rochester Hills'\n",
      " 'Plainfield' 'Sierra Vista' 'Vancouver' 'Cleveland' 'Tyler' 'Burlington'\n",
      " 'Waynesboro' 'Chester' 'Cary' 'Palm Coast' 'Mount Vernon' 'Hialeah'\n",
      " 'Oceanside' 'Evanston' 'Trenton' 'Cottage Grove' 'Bossier City'\n",
      " 'Lancaster' 'Asheville' 'Lake Elsinore' 'Omaha' 'Edmonds' 'Santa Ana'\n",
      " 'Milwaukee' 'Florence' 'Lorain' 'Linden' 'Salinas' 'New Brunswick'\n",
      " 'Garland' 'Norwich' 'Alexandria' 'Toledo' 'Farmington' 'Riverside'\n",
      " 'Torrance' 'Round Rock' 'Boca Raton' 'Virginia Beach' 'Murrieta'\n",
      " 'Olympia' 'Washington' 'Jefferson City' 'Saint Peters' 'Rockford'\n",
      " 'Brownsville' 'Yonkers' 'Oakland' 'Clinton' 'Encinitas' 'Roswell'\n",
      " 'Jonesboro' 'Antioch' 'Homestead' 'La Porte' 'Lansing' 'Cuyahoga Falls'\n",
      " 'Reno' 'Harrisonburg' 'Escondido' 'Royal Oak' 'Rockville' 'Coral Springs'\n",
      " 'Buffalo' 'Boynton Beach' 'Gulfport' 'Fresno' 'Greenville' 'Macon'\n",
      " 'Cedar Rapids' 'Providence' 'Pueblo' 'Deltona' 'Murray' 'Middletown'\n",
      " 'Freeport' 'Pico Rivera' 'Provo' 'Pleasant Grove' 'Smyrna' 'Parma'\n",
      " 'Mobile' 'New Bedford' 'Irving' 'Vineland' 'Glendale' 'Niagara Falls'\n",
      " 'Thomasville' 'Westminster' 'Coppell' 'Pomona' 'North Las Vegas'\n",
      " 'Allentown' 'Tempe' 'Laguna Niguel' 'Bridgeton' 'Everett' 'Watertown'\n",
      " 'Appleton' 'Bellevue' 'Allen' 'El Paso' 'Grapevine' 'Carrollton' 'Kent'\n",
      " 'Lafayette' 'Tigard' 'Skokie' 'Plano' 'Suffolk' 'Indianapolis' 'Bayonne'\n",
      " 'Greensboro' 'Baltimore' 'Kenosha' 'Olathe' 'Tulsa' 'Redmond' 'Raleigh'\n",
      " 'Muskogee' 'Meriden' 'Bowling Green' 'South Bend' 'Spokane' 'Keller'\n",
      " 'Port Orange' 'Medford' 'Charlottesville' 'Missoula' 'Apopka' 'Reading'\n",
      " 'Broomfield' 'Paterson' 'Oklahoma City' 'Chesapeake' 'Lubbock'\n",
      " 'Johnson City' 'San Bernardino' 'Leominster' 'Bozeman' 'Perth Amboy'\n",
      " 'Ontario' 'Rancho Cucamonga' 'Moorhead' 'Mesquite' 'Stockton'\n",
      " 'Ormond Beach' 'Sunnyvale' 'York' 'College Station' 'Saint Louis'\n",
      " 'Manteca' 'San Angelo' 'Salt Lake City' 'Knoxville' 'Little Rock'\n",
      " 'Lincoln Park' 'Marion' 'Littleton' 'Bangor' 'Southaven' 'New Castle'\n",
      " 'Midland' 'Sioux Falls' 'Fort Collins' 'Clarksville' 'Sacramento'\n",
      " 'Thousand Oaks' 'Malden' 'Holyoke' 'Albuquerque' 'Sparks' 'Coachella'\n",
      " 'Elmhurst' 'Passaic' 'North Charleston' 'Newport News' 'Jamestown'\n",
      " 'Mishawaka' 'La Quinta' 'Tallahassee' 'Nashville' 'Bellingham'\n",
      " 'Woodstock' 'Haltom City' 'Wheeling' 'Summerville' 'Hot Springs'\n",
      " 'Englewood' 'Las Cruces' 'Hoover' 'Frisco' 'Vacaville' 'Waukesha'\n",
      " 'Bakersfield' 'Pompano Beach' 'Corpus Christi' 'Redondo Beach' 'Orlando'\n",
      " 'Orange' 'Lake Charles' 'Highland Park' 'Hempstead' 'Noblesville'\n",
      " 'Apple Valley' 'Mount Pleasant' 'Sterling Heights' 'Eau Claire' 'Pharr'\n",
      " 'Billings' 'Gresham' 'Chattanooga' 'Meridian' 'Bolingbrook' 'Maple Grove'\n",
      " 'Woodland' 'Missouri City' 'Pearland' 'San Mateo' 'Grand Rapids'\n",
      " 'Visalia' 'Overland Park' 'Temecula' 'Yucaipa' 'Revere' 'Conroe'\n",
      " 'Tinley Park' 'Dubuque' 'Dearborn Heights' 'Santa Fe' 'Hickory'\n",
      " 'Carol Stream' 'Saint Cloud' 'North Miami' 'Plantation'\n",
      " 'Port Saint Lucie' 'Rock Hill' 'Odessa' 'West Allis' 'Chula Vista'\n",
      " 'Manhattan' 'Altoona' 'Thornton' 'Champaign' 'Texarkana' 'Edinburg'\n",
      " 'Baytown' 'Greenwood' 'Woonsocket' 'Superior' 'Bedford' 'Covington'\n",
      " 'Broken Arrow' 'Miramar' 'Hollywood' 'Deer Park' 'Wichita' 'Mcallen'\n",
      " 'Iowa City' 'Boise' 'Cranston' 'Port Arthur' 'Citrus Heights'\n",
      " 'The Colony' 'Daytona Beach' 'Bullhead City' 'Portage' 'Fargo' 'Elkhart'\n",
      " 'San Gabriel' 'Margate' 'Sandy Springs' 'Mentor' 'Lawton' 'Hampton'\n",
      " 'Rome' 'La Crosse' 'Lewiston' 'Hattiesburg' 'Danville' 'Logan'\n",
      " 'Waterbury' 'Athens' 'Avondale' 'Marietta' 'Yuma' 'Wausau' 'Pasco'\n",
      " 'Oak Park' 'Pensacola' 'League City' 'Gaithersburg' 'Lehi' 'Tuscaloosa'\n",
      " 'Moreno Valley' 'Georgetown' 'Loveland' 'Chandler' 'Helena' 'Kirkwood'\n",
      " 'Waco' 'Frankfort' 'Bethlehem' 'Grand Island' 'Woodbury' 'Rogers'\n",
      " 'Clovis' 'Jupiter' 'Santa Barbara' 'Cedar Hill' 'Norfolk' 'Draper'\n",
      " 'Ann Arbor' 'La Mesa' 'Pocatello' 'Holland' 'Milford' 'Buffalo Grove'\n",
      " 'Lake Forest' 'Redding' 'Chico' 'Utica' 'Conway' 'Cheyenne' 'Owensboro'\n",
      " 'Caldwell' 'Kenner' 'Nashua' 'Bartlett' 'Redwood City' 'Lebanon'\n",
      " 'Santa Maria' 'Des Plaines' 'Longview' 'Hendersonville' 'Waterloo'\n",
      " 'Cambridge' 'Palatine' 'Beverly' 'Eugene' 'Oxnard' 'Renton' 'Glenview'\n",
      " 'Delray Beach' 'Commerce City' 'Texas City' 'Wilson' 'Rio Rancho'\n",
      " 'Goldsboro' 'Montebello' 'El Cajon' 'Beaumont' 'West Palm Beach'\n",
      " 'Abilene' 'Normal' 'Saint Charles' 'Camarillo' 'Hillsboro' 'Burbank'\n",
      " 'Modesto' 'Garden City' 'Atlantic City' 'Longmont' 'Davis' 'Morgan Hill'\n",
      " 'Clifton' 'Sheboygan' 'East Point' 'Rapid City' 'Andover' 'Kissimmee'\n",
      " 'Shelton' 'Danbury' 'Sanford' 'San Marcos' 'Greeley' 'Mansfield' 'Elyria'\n",
      " 'Twin Falls' 'Coral Gables' 'Romeoville' 'Marlborough' 'Laurel' 'Bryan'\n",
      " 'Pine Bluff' 'Aberdeen' 'Hagerstown' 'East Orange' 'Arlington Heights'\n",
      " 'Oswego' 'Coon Rapids' 'San Clemente' 'San Luis Obispo' 'Springdale'\n",
      " 'Lodi' 'Mason']\n"
     ]
    }
   ],
   "source": [
    "# City column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"City\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5da0631f-0f15-48c0-b1f4-6d07f0a2dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Kentucky' 'California' 'Florida' 'North Carolina' 'Washington' 'Texas'\n",
      " 'Wisconsin' 'Utah' 'Nebraska' 'Pennsylvania' 'Illinois' 'Minnesota'\n",
      " 'Michigan' 'Delaware' 'Indiana' 'New York' 'Arizona' 'Virginia'\n",
      " 'Tennessee' 'Alabama' 'South Carolina' 'Oregon' 'Colorado' 'Iowa' 'Ohio'\n",
      " 'Missouri' 'Oklahoma' 'New Mexico' 'Louisiana' 'Connecticut' 'New Jersey'\n",
      " 'Massachusetts' 'Georgia' 'Nevada' 'Rhode Island' 'Mississippi'\n",
      " 'Arkansas' 'Montana' 'New Hampshire' 'Maryland' 'District of Columbia'\n",
      " 'Kansas' 'Vermont' 'Maine' 'South Dakota' 'Idaho' 'North Dakota'\n",
      " 'Wyoming' 'West Virginia']\n"
     ]
    }
   ],
   "source": [
    "# State column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"State\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ca373a0-6c13-40c7-aaf3-64381a73acae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Furniture' 'Office Supplies' 'Technology']\n"
     ]
    }
   ],
   "source": [
    "# Category column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Category\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8553ab22-c7df-47e3-ba52-1adf4e583d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['Bookcases' 'Chairs' 'Labels' 'Tables' 'Storage' 'Furnishings' 'Art'\n",
      " 'Phones' 'Binders' 'Appliances' 'Paper' 'Accessories' 'Envelopes'\n",
      " 'Fasteners' 'Supplies' 'Machines' 'Copiers']\n"
     ]
    }
   ],
   "source": [
    "# Sub_Category column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Sub-Category\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "110ab005-7365-4777-90ea-11c6b6428253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values are:\n",
      "['11/8/2016' '6/12/2016' '10/11/2015' ... '6/3/2016' '4/12/2015'\n",
      " '1/21/2014']\n"
     ]
    }
   ],
   "source": [
    "# Order Date column Analysis\n",
    "# Examine the distinct values to check if there is leading or trailing spaces.\n",
    "unique_values = df[\"Order Date\"].unique()\n",
    "print( f\"Distinct values are:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f112ee-d226-4bda-8858-9eed28a00558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                                      feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40ef017-f8d4-49d0-8630-257cdb8d85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ship date(work with order date) and customer name columns,\n",
    "df = df.drop(columns=[\"Ship Date\", \"Customer Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "178d3750-4641-429e-98f8-ed937e6b5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date       Ship Mode Customer ID    Segment  \\\n",
      "0       1  CA-2016-152156   11/8/2016    Second Class    CG-12520   Consumer   \n",
      "1       2  CA-2016-152156   11/8/2016    Second Class    CG-12520   Consumer   \n",
      "2       3  CA-2016-138688   6/12/2016    Second Class    DV-13045  Corporate   \n",
      "3       4  US-2015-108966  10/11/2015  Standard Class    SO-20335   Consumer   \n",
      "4       5  US-2015-108966  10/11/2015  Standard Class    SO-20335   Consumer   \n",
      "\n",
      "         Country             City       State  Postal Code Region  \\\n",
      "0  United States        Henderson    Kentucky        42420  South   \n",
      "1  United States        Henderson    Kentucky        42420  South   \n",
      "2  United States      Los Angeles  California        90036   West   \n",
      "3  United States  Fort Lauderdale     Florida        33311  South   \n",
      "4  United States  Fort Lauderdale     Florida        33311  South   \n",
      "\n",
      "        Product ID         Category Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "(9994, 19)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dda2ad3-8e06-4d3f-b77a-dd63282873af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert order date to datetype so as to extract, day, month and year columns\n",
    "df['Order Date'] = pd.to_datetime(df['Order Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2bfcf11-0af4-48ec-badb-55c270ff8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract day, month and year columns\n",
    "df['Day'] = df['Order Date'].dt.day\n",
    "df['Month'] = df['Order Date'].dt.month              # <-- Numeric month (1–12)\n",
    "df['Month Name'] = df['Order Date'].dt.month_name()  # <-- Full month name\n",
    "df['Year'] = df['Order Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eeed03-7b51-493f-8b23-78223363d2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9db6473c-d52d-4b80-81b6-c508bba45540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID Order Date       Ship Mode Customer ID    Segment  \\\n",
      "0       1  CA-2016-152156 2016-11-08    Second Class    CG-12520   Consumer   \n",
      "1       2  CA-2016-152156 2016-11-08    Second Class    CG-12520   Consumer   \n",
      "2       3  CA-2016-138688 2016-06-12    Second Class    DV-13045  Corporate   \n",
      "3       4  US-2015-108966 2015-10-11  Standard Class    SO-20335   Consumer   \n",
      "4       5  US-2015-108966 2015-10-11  Standard Class    SO-20335   Consumer   \n",
      "\n",
      "         Country             City       State  Postal Code  ... Sub-Category  \\\n",
      "0  United States        Henderson    Kentucky        42420  ...    Bookcases   \n",
      "1  United States        Henderson    Kentucky        42420  ...       Chairs   \n",
      "2  United States      Los Angeles  California        90036  ...       Labels   \n",
      "3  United States  Fort Lauderdale     Florida        33311  ...       Tables   \n",
      "4  United States  Fort Lauderdale     Florida        33311  ...      Storage   \n",
      "\n",
      "                                        Product Name     Sales Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600        2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400        3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200        2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775        5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680        2   \n",
      "\n",
      "  Discount    Profit  Day  Month  Month Name  Year  \n",
      "0     0.00   41.9136    8     11    November  2016  \n",
      "1     0.00  219.5820    8     11    November  2016  \n",
      "2     0.00    6.8714   12      6        June  2016  \n",
      "3     0.45 -383.0310   11     10     October  2015  \n",
      "4     0.20    2.5164   11     10     October  2015  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "(9994, 23)\n"
     ]
    }
   ],
   "source": [
    "# view the dataframe to see if they have been added.\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86f53144-9a17-41b1-8675-aa95660a1aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Ship Mode  Ship Mode ID\n",
      "0    Second Class             1\n",
      "1    Second Class             1\n",
      "2    Second Class             1\n",
      "3  Standard Class             2\n",
      "4  Standard Class             2\n"
     ]
    }
   ],
   "source": [
    "# Generate a mapping of 'Ship Mode' to a unique ID\n",
    "ship_mode_mapping = {ship_mode: idx for idx, ship_mode in enumerate(df['Ship Mode'].unique(), 1)}\n",
    "\n",
    "# Apply this mapping to create a new 'Ship Mode ID' column\n",
    "df['Ship Mode ID'] = df['Ship Mode'].map(ship_mode_mapping)\n",
    "\n",
    "# Check the result\n",
    "print(df[['Ship Mode', 'Ship Mode ID']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f73007d-522f-4b02-91e0-47aa0d24045b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Country             City       State Region  Geo ID\n",
      "0  United States        Henderson    Kentucky  South       1\n",
      "1  United States        Henderson    Kentucky  South       1\n",
      "2  United States      Los Angeles  California   West       2\n",
      "3  United States  Fort Lauderdale     Florida  South       3\n",
      "4  United States  Fort Lauderdale     Florida  South       3\n"
     ]
    }
   ],
   "source": [
    "# Create a unique combination of the columns; Country, City, State, and Region\n",
    "df['Geo Combination'] = df['Country'] + \" | \" + df['City'] + \" | \" + df['State'] + \" | \" + df['Region']\n",
    "\n",
    "# Generate Geo ID using factorize (this will create unique IDs based on the unique Geo combinations)\n",
    "df['Geo ID'] = pd.factorize(df['Geo Combination'])[0] + 1  # Start IDs from 1\n",
    "\n",
    "# Check the result\n",
    "print(df[['Country', 'City', 'State', 'Region', 'Geo ID']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75291541-a76b-4961-82a4-33d2c7c5ac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ship Mode ID</th>\n",
       "      <th>Geo Combination</th>\n",
       "      <th>Geo ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>November</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>United States | Henderson | Kentucky | South</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>November</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>United States | Henderson | Kentucky | South</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>90036</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>United States | Los Angeles | California | West</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>United States | Fort Lauderdale | Florida | South</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>33311</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>United States | Fort Lauderdale | Florida | South</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date       Ship Mode Customer ID    Segment  \\\n",
       "0       1  CA-2016-152156 2016-11-08    Second Class    CG-12520   Consumer   \n",
       "1       2  CA-2016-152156 2016-11-08    Second Class    CG-12520   Consumer   \n",
       "2       3  CA-2016-138688 2016-06-12    Second Class    DV-13045  Corporate   \n",
       "3       4  US-2015-108966 2015-10-11  Standard Class    SO-20335   Consumer   \n",
       "4       5  US-2015-108966 2015-10-11  Standard Class    SO-20335   Consumer   \n",
       "\n",
       "         Country             City       State  Postal Code  ... Quantity  \\\n",
       "0  United States        Henderson    Kentucky        42420  ...        2   \n",
       "1  United States        Henderson    Kentucky        42420  ...        3   \n",
       "2  United States      Los Angeles  California        90036  ...        2   \n",
       "3  United States  Fort Lauderdale     Florida        33311  ...        5   \n",
       "4  United States  Fort Lauderdale     Florida        33311  ...        2   \n",
       "\n",
       "  Discount    Profit Day Month  Month Name  Year  Ship Mode ID  \\\n",
       "0     0.00   41.9136   8    11    November  2016             1   \n",
       "1     0.00  219.5820   8    11    November  2016             1   \n",
       "2     0.00    6.8714  12     6        June  2016             1   \n",
       "3     0.45 -383.0310  11    10     October  2015             2   \n",
       "4     0.20    2.5164  11    10     October  2015             2   \n",
       "\n",
       "                                     Geo Combination  Geo ID  \n",
       "0       United States | Henderson | Kentucky | South       1  \n",
       "1       United States | Henderson | Kentucky | South       1  \n",
       "2    United States | Los Angeles | California | West       2  \n",
       "3  United States | Fort Lauderdale | Florida | South       3  \n",
       "4  United States | Fort Lauderdale | Florida | South       3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3de7561a-c4a0-456b-80ac-b6774c71511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Geo Combination' column\n",
    "df = df.drop(columns=['Geo Combination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a9694e-aa9d-416b-9d75-017da5c275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#                                  Save the prepared and cleaned dataset as a csv to document.\n",
    "df.to_csv(r\"C:\\Users\\USER\\Documents\\Cleaned_Sales_data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cbac957-3f92-4edc-81f1-34e987ed98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Row ID        Order ID  Order Date       Ship Mode Customer ID    Segment  \\\n",
      "0       1  CA-2016-152156  2016-11-08    Second Class    CG-12520   Consumer   \n",
      "1       2  CA-2016-152156  2016-11-08    Second Class    CG-12520   Consumer   \n",
      "2       3  CA-2016-138688  2016-06-12    Second Class    DV-13045  Corporate   \n",
      "3       4  US-2015-108966  2015-10-11  Standard Class    SO-20335   Consumer   \n",
      "4       5  US-2015-108966  2015-10-11  Standard Class    SO-20335   Consumer   \n",
      "\n",
      "         Country             City       State  Postal Code  ...     Sales  \\\n",
      "0  United States        Henderson    Kentucky        42420  ...  261.9600   \n",
      "1  United States        Henderson    Kentucky        42420  ...  731.9400   \n",
      "2  United States      Los Angeles  California        90036  ...   14.6200   \n",
      "3  United States  Fort Lauderdale     Florida        33311  ...  957.5775   \n",
      "4  United States  Fort Lauderdale     Florida        33311  ...   22.3680   \n",
      "\n",
      "  Quantity Discount    Profit Day  Month  Month Name  Year  Ship Mode ID  \\\n",
      "0        2     0.00   41.9136   8     11    November  2016             1   \n",
      "1        3     0.00  219.5820   8     11    November  2016             1   \n",
      "2        2     0.00    6.8714  12      6        June  2016             1   \n",
      "3        5     0.45 -383.0310  11     10     October  2015             2   \n",
      "4        2     0.20    2.5164  11     10     October  2015             2   \n",
      "\n",
      "   Geo ID  \n",
      "0       1  \n",
      "1       1  \n",
      "2       2  \n",
      "3       3  \n",
      "4       3  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the saved dataset for fact and dimensins table creation so as to be able to form one-to-many relationship.\n",
    "\n",
    "# Specify file path\n",
    "import pandas as pd\n",
    "file_path = r\"C:\\Users\\USER\\Documents\\Cleaned_Sales_data2.csv\"\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "#df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "842a6f2e-c87e-4fd1-ae5f-35ffe840422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>...</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Month Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ship Mode ID</th>\n",
       "      <th>Geo ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>November</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>November</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>2016-06-12</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>South</td>\n",
       "      <td>...</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>October</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date       Ship Mode Customer ID    Segment  \\\n",
       "0       1  CA-2016-152156  2016-11-08    Second Class    CG-12520   Consumer   \n",
       "1       2  CA-2016-152156  2016-11-08    Second Class    CG-12520   Consumer   \n",
       "2       3  CA-2016-138688  2016-06-12    Second Class    DV-13045  Corporate   \n",
       "3       4  US-2015-108966  2015-10-11  Standard Class    SO-20335   Consumer   \n",
       "4       5  US-2015-108966  2015-10-11  Standard Class    SO-20335   Consumer   \n",
       "\n",
       "         Country             City       State Region  ...     Sales Quantity  \\\n",
       "0  United States        Henderson    Kentucky  South  ...  261.9600        2   \n",
       "1  United States        Henderson    Kentucky  South  ...  731.9400        3   \n",
       "2  United States      Los Angeles  California   West  ...   14.6200        2   \n",
       "3  United States  Fort Lauderdale     Florida  South  ...  957.5775        5   \n",
       "4  United States  Fort Lauderdale     Florida  South  ...   22.3680        2   \n",
       "\n",
       "  Discount    Profit  Day  Month  Month Name  Year  Ship Mode ID  Geo ID  \n",
       "0     0.00   41.9136    8     11    November  2016             1       1  \n",
       "1     0.00  219.5820    8     11    November  2016             1       1  \n",
       "2     0.00    6.8714   12      6        June  2016             1       2  \n",
       "3     0.45 -383.0310   11     10     October  2015             2       3  \n",
       "4     0.20    2.5164   11     10     October  2015             2       3  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff4ba53e-66f9-4326-9ea1-6d95c7f34633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Order ID  Order Date Customer ID       Product ID  Ship Mode ID  \\\n",
      "0  CA-2016-152156  2016-11-08    CG-12520  FUR-BO-10001798             1   \n",
      "1  CA-2016-152156  2016-11-08    CG-12520  FUR-CH-10000454             1   \n",
      "2  CA-2016-138688  2016-06-12    DV-13045  OFF-LA-10000240             1   \n",
      "3  US-2015-108966  2015-10-11    SO-20335  FUR-TA-10000577             2   \n",
      "4  US-2015-108966  2015-10-11    SO-20335  OFF-ST-10000760             2   \n",
      "\n",
      "   Geo ID     Sales  Quantity  Discount    Profit  \n",
      "0       1  261.9600         2      0.00   41.9136  \n",
      "1       1  731.9400         3      0.00  219.5820  \n",
      "2       2   14.6200         2      0.00    6.8714  \n",
      "3       3  957.5775         5      0.45 -383.0310  \n",
      "4       3   22.3680         2      0.20    2.5164  \n"
     ]
    }
   ],
   "source": [
    "#     fact table creation.\n",
    "# Create the fact table with all specified columns\n",
    "fact_table = df[['Order ID', 'Order Date', 'Customer ID', 'Product ID',\n",
    "                 'Ship Mode ID', 'Geo ID', 'Sales', 'Quantity', 'Discount', 'Profit']].copy()\n",
    "\n",
    "# Preview the fact table\n",
    "print(fact_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8e1ea541-7086-4880-bd79-5674fe379cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fact table as csv to document\n",
    "fact_table.to_csv(r'C:\\Users\\USER\\Documents\\fact_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ecb05f1-0237-4ce6-9d96-0822cc4e13c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ship Mode ID\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: count, dtype: int64\n",
      "     Ship Mode ID       Ship Mode\n",
      "0               1    Second Class\n",
      "3               2  Standard Class\n",
      "35              3     First Class\n",
      "366             4        Same Day\n"
     ]
    }
   ],
   "source": [
    "# Create ship mode dimension  table with all specified column.\n",
    "\n",
    "Dim_ship = df[['Ship Mode ID', 'Ship Mode']].copy()\n",
    "Dim_ship = Dim_ship.drop_duplicates(subset='Ship Mode ID')\n",
    "print(Dim_ship['Ship Mode ID'].value_counts())\n",
    "\n",
    "# Preview the created ship mode dimension table\n",
    "print(Dim_ship.head())\n",
    "#  Save it as csv to document\n",
    "Dim_ship.to_csv(r'C:\\Users\\USER\\Documents\\Dim_ship.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f95a3186-ef49-4f09-bc62-12ff33145fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer ID\n",
      "SM-20905    1\n",
      "CG-12520    1\n",
      "DV-13045    1\n",
      "SO-20335    1\n",
      "BH-11710    1\n",
      "           ..\n",
      "EH-13945    1\n",
      "EB-13870    1\n",
      "SF-20065    1\n",
      "KB-16585    1\n",
      "ZD-21925    1\n",
      "Name: count, Length: 793, dtype: int64\n",
      "   Customer ID    Segment\n",
      "0     CG-12520   Consumer\n",
      "2     DV-13045  Corporate\n",
      "3     SO-20335   Consumer\n",
      "5     BH-11710   Consumer\n",
      "12    AA-10480   Consumer\n"
     ]
    }
   ],
   "source": [
    "# create customer dimension table\n",
    "Dim_customer = df[['Customer ID', 'Segment']].copy()\n",
    "Dim_customer = Dim_customer.drop_duplicates(subset='Customer ID')\n",
    "\n",
    "print(Dim_customer['Customer ID'].value_counts())\n",
    "\n",
    "# Preview the fact table\n",
    "print(Dim_customer.head())\n",
    "# Save it as csv file\n",
    "Dim_customer.to_csv(r'C:\\Users\\USER\\Documents\\Dim_customer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9b9678a-4e40-47b1-beae-3b167da8ed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geo ID\n",
      "604    1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "17     1\n",
      "16     1\n",
      "15     1\n",
      "14     1\n",
      "13     1\n",
      "Name: count, Length: 604, dtype: int64\n",
      "    Geo ID  Postal Code        Country Region           State             City\n",
      "0        1        42420  United States  South        Kentucky        Henderson\n",
      "2        2        90036  United States   West      California      Los Angeles\n",
      "3        3        33311  United States  South         Florida  Fort Lauderdale\n",
      "12       4        28027  United States  South  North Carolina          Concord\n",
      "13       5        98103  United States   West      Washington          Seattle\n"
     ]
    }
   ],
   "source": [
    "# create geography dimension table\n",
    "Dim_geography = df[['Geo ID', 'Postal Code', 'Country', 'Region', 'State', 'City']].copy()\n",
    "\n",
    "Dim_geography = Dim_geography.drop_duplicates(subset='Geo ID')\n",
    "\n",
    "print(Dim_geography['Geo ID'].value_counts())\n",
    "\n",
    "# Preview the fact table\n",
    "print(Dim_geography.head())\n",
    "# save it as csv\n",
    "Dim_geography.to_csv(r'C:\\Users\\USER\\Documents\\Dim_geography.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ad02afc2-64a9-470e-b10f-fd8039595803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID\n",
      "OFF-ST-10001627    1\n",
      "FUR-BO-10001798    1\n",
      "FUR-CH-10000454    1\n",
      "OFF-LA-10000240    1\n",
      "FUR-TA-10000577    1\n",
      "                  ..\n",
      "FUR-TA-10001539    1\n",
      "OFF-AP-10002892    1\n",
      "OFF-BI-10003910    1\n",
      "TEC-PH-10002275    1\n",
      "OFF-AR-10002833    1\n",
      "Name: count, Length: 1862, dtype: int64\n",
      "        Product ID         Category Sub-Category  \\\n",
      "0  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1  FUR-CH-10000454        Furniture       Chairs   \n",
      "2  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3  FUR-TA-10000577        Furniture       Tables   \n",
      "4  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name  \n",
      "0                  Bush Somerset Collection Bookcase  \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  \n",
      "2  Self-Adhesive Address Labels for Typewriters b...  \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  \n",
      "4                     Eldon Fold 'N Roll Cart System  \n"
     ]
    }
   ],
   "source": [
    "# create product dimension table\n",
    "Dim_product = df[['Product ID', 'Category', 'Sub-Category', 'Product Name']].copy()\n",
    "\n",
    "Dim_product = Dim_product.drop_duplicates(subset='Product ID')\n",
    "\n",
    "print(Dim_product['Product ID'].value_counts())\n",
    "\n",
    "# Preview the table\n",
    "print(Dim_product.head())\n",
    "# save it as csv file.\n",
    "Dim_product.to_csv(r'C:\\Users\\USER\\Documents\\Dim_product.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a8a5ac6a-f036-42ae-8054-c3a137ca4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Date\n",
      "2014-01-21    1\n",
      "2016-11-08    1\n",
      "2016-06-12    1\n",
      "2015-10-11    1\n",
      "2014-06-09    1\n",
      "             ..\n",
      "2014-08-27    1\n",
      "2014-05-13    1\n",
      "2014-11-11    1\n",
      "2015-11-22    1\n",
      "2016-12-05    1\n",
      "Name: count, Length: 1237, dtype: int64\n",
      "    Order Date  Day  Month Month Name  Year\n",
      "0   2016-11-08    8     11   November  2016\n",
      "2   2016-06-12   12      6       June  2016\n",
      "3   2015-10-11   11     10    October  2015\n",
      "5   2014-06-09    9      6       June  2014\n",
      "12  2017-04-15   15      4      April  2017\n"
     ]
    }
   ],
   "source": [
    "# create time dimension table\n",
    "Dim_Date = df[['Order Date', 'Day', 'Month', 'Month Name', 'Year']].copy()\n",
    "\n",
    "Dim_Date = Dim_Date.drop_duplicates(subset='Order Date')\n",
    "\n",
    "print(Dim_Date['Order Date'].value_counts())\n",
    "\n",
    "# Preview the table\n",
    "print(Dim_Date.head())\n",
    "# save it as csv file.\n",
    "Dim_Date.to_csv(r'C:\\Users\\USER\\Documents\\Dim_Date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ec1bb-298e-4d1c-9334-11fe57a1f8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
